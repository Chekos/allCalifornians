{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# To be continued tomorrow:\n",
    "create sentence fragments from columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data analysis\n",
    "import gzip         # to work with zip files \n",
    "import spacy        # for NLP (dealing with occupations)\n",
    "\n",
    "# this changes the settings in your Jupyter Notebook so it displays multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datanum</th>\n",
       "      <th>serial</th>\n",
       "      <th>countyfips</th>\n",
       "      <th>city</th>\n",
       "      <th>gq</th>\n",
       "      <th>farm</th>\n",
       "      <th>ownershp</th>\n",
       "      <th>ownershpd</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>mortgag2</th>\n",
       "      <th>...</th>\n",
       "      <th>pwstate2</th>\n",
       "      <th>tranwork</th>\n",
       "      <th>carpool</th>\n",
       "      <th>riders</th>\n",
       "      <th>trantime</th>\n",
       "      <th>departs</th>\n",
       "      <th>arrives</th>\n",
       "      <th>occ_lemma</th>\n",
       "      <th>occ_tag</th>\n",
       "      <th>occ_nnps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67752</td>\n",
       "      <td>Tulare</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>non-farm</td>\n",
       "      <td>owned or being bought (loan)</td>\n",
       "      <td>owned free and clear</td>\n",
       "      <td>no, owned free and clear</td>\n",
       "      <td>n/a</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>67752</td>\n",
       "      <td>Tulare</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>non-farm</td>\n",
       "      <td>owned or being bought (loan)</td>\n",
       "      <td>owned free and clear</td>\n",
       "      <td>no, owned free and clear</td>\n",
       "      <td>n/a</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>67753</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>non-farm</td>\n",
       "      <td>owned or being bought (loan)</td>\n",
       "      <td>owned with mortgage or loan</td>\n",
       "      <td>yes, mortgaged/ deed of trust or similar debt</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>california</td>\n",
       "      <td>auto, truck, or van</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>22</td>\n",
       "      <td>1105</td>\n",
       "      <td>1124</td>\n",
       "      <td>retail, salesperson</td>\n",
       "      <td>salesperson</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>67753</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>non-farm</td>\n",
       "      <td>owned or being bought (loan)</td>\n",
       "      <td>owned with mortgage or loan</td>\n",
       "      <td>yes, mortgaged/ deed of trust or similar debt</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>california</td>\n",
       "      <td>auto, truck, or van</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>drives alone</td>\n",
       "      <td>141</td>\n",
       "      <td>502</td>\n",
       "      <td>704</td>\n",
       "      <td>retail, salesperson</td>\n",
       "      <td>salesperson</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>67753</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>not in identifiable city (or size group)</td>\n",
       "      <td>households under 1970 definition</td>\n",
       "      <td>non-farm</td>\n",
       "      <td>owned or being bought (loan)</td>\n",
       "      <td>owned with mortgage or loan</td>\n",
       "      <td>yes, mortgaged/ deed of trust or similar debt</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   datanum  serial countyfips                                      city  \\\n",
       "0        1   67752     Tulare  not in identifiable city (or size group)   \n",
       "1        1   67752     Tulare  not in identifiable city (or size group)   \n",
       "2        1   67753  Riverside  not in identifiable city (or size group)   \n",
       "3        1   67753  Riverside  not in identifiable city (or size group)   \n",
       "4        1   67753  Riverside  not in identifiable city (or size group)   \n",
       "\n",
       "                                 gq      farm                      ownershp  \\\n",
       "0  households under 1970 definition  non-farm  owned or being bought (loan)   \n",
       "1  households under 1970 definition  non-farm  owned or being bought (loan)   \n",
       "2  households under 1970 definition  non-farm  owned or being bought (loan)   \n",
       "3  households under 1970 definition  non-farm  owned or being bought (loan)   \n",
       "4  households under 1970 definition  non-farm  owned or being bought (loan)   \n",
       "\n",
       "                     ownershpd                                       mortgage  \\\n",
       "0         owned free and clear                       no, owned free and clear   \n",
       "1         owned free and clear                       no, owned free and clear   \n",
       "2  owned with mortgage or loan  yes, mortgaged/ deed of trust or similar debt   \n",
       "3  owned with mortgage or loan  yes, mortgaged/ deed of trust or similar debt   \n",
       "4  owned with mortgage or loan  yes, mortgaged/ deed of trust or similar debt   \n",
       "\n",
       "  mortgag2    ...       pwstate2             tranwork       carpool  \\\n",
       "0      n/a    ...            n/a                  n/a           n/a   \n",
       "1      n/a    ...            n/a                  n/a           n/a   \n",
       "2       no    ...     california  auto, truck, or van  drives alone   \n",
       "3       no    ...     california  auto, truck, or van  drives alone   \n",
       "4       no    ...            n/a                  n/a           n/a   \n",
       "\n",
       "         riders  trantime  departs arrives            occ_lemma      occ_tag  \\\n",
       "0           n/a         0        0       0                                     \n",
       "1           n/a         0        0       0                                     \n",
       "2  drives alone        22     1105    1124  retail, salesperson  salesperson   \n",
       "3  drives alone       141      502     704  retail, salesperson  salesperson   \n",
       "4           n/a         0        0       0                                     \n",
       "\n",
       "   occ_nnps  \n",
       "0            \n",
       "1            \n",
       "2            \n",
       "3            \n",
       "4            \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading from check-point\n",
    "with gzip.open(\"../data/processed/working-101718_dataset.dta.gz\", \"rb\") as datafile:\n",
    "    working_df = pd.read_stata(datafile)\n",
    "    \n",
    "working_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Because we will not be using every single one of these 130 columns we can start dropping some. <br>\n",
    "The following I'll choose based on what I want my twitterbot to tweet, you may choose to keep whatever variable you're interested in if you are going to be using this dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make a list of variables to drop\n",
    "income_vars = [col for col in working_df.columns if \"inc\" in col]\n",
    "\n",
    "income_vars.remove(\"incwage\") # we want to keep these\n",
    "income_vars.remove(\"inctot\")\n",
    "\n",
    "working_df.drop(columns=income_vars, inplace = True)\n",
    "\n",
    "# Repeat the process for other groups of variables\n",
    "vet_vars = [col for col in working_df.columns if \"vet\" in col]\n",
    "\n",
    "vet_vars.remove(\"vetstat\")\n",
    "\n",
    "working_df.drop(columns=vet_vars, inplace = True)\n",
    "\n",
    "# randoms\n",
    "other_vars = ['lingisol','city','multgend','ind','bpld','uhrswork','yrnatur', 'citizen','yrimmig','availble', 'foodstmp','marrno', 'divinyr', 'widinyr','wkswork2','mortgage', 'degfield', 'rentmeal','gq', 'degfield2','ownershp', 'ownershpd', 'mortgag2', 'farmprod', 'acrehous', 'mortamt1', 'mortamt2', 'rentgrs', 'fridge', 'hotwater', 'bedrooms', 'phone', 'cinethh', 'cilaptop', 'cismrtphn', 'citablet', 'ciothcomp', 'cidatapln', 'fuelheat', 'nfams', 'nsubfam', 'ncouples', 'birthyr', 'raced', 'race', 'hispan', 'hispand', 'ancestr1', 'ancestr2', 'languaged', 'educ', 'gradeatt', 'schltype', 'degfieldd', 'degfield2d', 'empstatd', 'classwkr', 'classwkrd', 'migrate1d', 'movedin']\n",
    "\n",
    "working_df.drop(columns=other_vars, inplace = True)\n",
    "\n",
    "# cost\n",
    "cost_vars = [col for col in working_df.columns if 'cost' in col]\n",
    "\n",
    "working_df.drop(columns=cost_vars, inplace = True)\n",
    "\n",
    "# health insurance\n",
    "health_vars = [col for col in working_df.columns if 'hins' in col]\n",
    "\n",
    "working_df.drop(columns=health_vars, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "You can save this trimmed dataset and start working on building your sentences from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"../data/processed/working-101818-cleaned_dataset.dta.gz\", \"wb\") as file:\n",
    "    working_df.to_stata(file, write_index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing sentences\n",
    "\n",
    "Based on the variables left I put came up with 11 different categories.\n",
    "\n",
    "1. Demographics:\n",
    "  - countyfips, sex, age, marst, yrmarr,\n",
    "2. Household:\n",
    "  - farm, rent, vehicles, ssmc, multgen\n",
    "3. Work:\n",
    "  - empstat, labforce, occ, looking, pwstate2, occ_lemma, occ_tag, occ_nnps\n",
    "4. Origin\n",
    "  - bpl, ancestr1d, ancestr2d, yrsusa1\n",
    "5. Language\n",
    "  - language\n",
    "6. Health coverage:\n",
    "  - hcovany\n",
    "7. Veteran\n",
    "  - vetstat\n",
    "8. Education\n",
    "  - educd, gradeattd\n",
    "9. Money\n",
    "  - inctot, incwage, poverty\n",
    "10. Moving\n",
    "  - migrate1, migplac1\n",
    "11. Commute\n",
    "  - tranwork, carpool, riders, trantime, departs, arrives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these categories we can create 11 potential sentence fragments. Of course, not all observations will have all 11 fragments.\n",
    "\n",
    "Before moving to the code itself it's a good idea to map out the logic for each fragment in ___pseudo-code___:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Demographics\n",
    "\n",
    "`countyfips`, `age`, and `sex` are values we can expect from every observation so we can build a sentence from there. The other variables _could or could not_ have values depending on whether a person is married or not (`marst`).\n",
    "\n",
    "An example sentence:<br>\n",
    "```python\n",
    "sentence = \"I'm {age}, from {countyfips}\"\n",
    "if sex == 'male':\n",
    "    sentence += man emoji\n",
    "else:\n",
    "    sentence += woman emoji\n",
    "\n",
    "if age >= 18:\n",
    "    if marst == \"never married/single\":\n",
    "        sentence = sentence + \". I'm single\"\n",
    "    elif \"married\" in marst:\n",
    "        sentence += \"I got married in {yrmarr}\"\n",
    "    else:\n",
    "        sentence += first word of marst ## divorced, separated, or widowed.\n",
    "else:\n",
    "    pass\n",
    "```\n",
    "\n",
    "So you end up with either <br>\n",
    "_\"I'm 16 {emoji}, from San Diego county\"_ or <br>\n",
    "_\"I'm 34 {emoji}, from Alameda county. I got married in 2007.\"_ or <br>\n",
    "_\"I'm 40 {emoji}, from Los Angeles county. I'm divorced.\"_\n",
    "\n",
    "***\n",
    "emoji unicode from: https://unicode.org/emoji/charts/full-emoji-list.html\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "boy_emoji = \"\\U0001F466\"\n",
    "girl_emoji = \"\\U0001F467\"\n",
    "man_emoji = \"\\U0001F468\"\n",
    "woman_emoji = \"\\U0001F469\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence starter\n",
    "working_df['demographics_sentence'] = \"I am\"\n",
    "working_df['demographics_sentence'] = working_df['demographics_sentence'] + \" \" + working_df['age'].astype(str) + ', from ' + working_df['countyfips'].astype(str).str.title() \n",
    "\n",
    "# emojis\n",
    "working_df.loc[((working_df['sex'] == 'male') & (working_df['age'] < '18')), 'demographics_sentence'] = working_df.loc[((working_df['sex'] == 'male') & (working_df['age'] < '18')), 'demographics_sentence'] + \" \" + boy_emoji\n",
    "working_df.loc[((working_df['sex'] == 'male') & (working_df['age'] >= '18')), 'demographics_sentence'] = working_df.loc[((working_df['sex'] == 'male') & (working_df['age'] >= '18')), 'demographics_sentence'] + \" \" + man_emoji\n",
    "\n",
    "working_df.loc[((working_df['sex'] == 'female') & (working_df['age'] < '18')), 'demographics_sentence'] = working_df.loc[((working_df['sex'] == 'female') & (working_df['age'] < '18')), 'demographics_sentence'] + \" \" + girl_emoji\n",
    "working_df.loc[((working_df['sex'] == 'female') & (working_df['age'] >= '18')), 'demographics_sentence'] = working_df.loc[((working_df['sex'] == 'female') & (working_df['age'] >= '18')), 'demographics_sentence'] + \" \" + woman_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I am 68, from Tulare ðŸ‘©\n",
       "1       I am 75, from Tulare ðŸ‘¨\n",
       "2    I am 50, from Riverside ðŸ‘©\n",
       "3    I am 49, from Riverside ðŸ‘¨\n",
       "4    I am 22, from Riverside ðŸ‘¨\n",
       "Name: demographics_sentence, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df['demographics_sentence'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Household\n",
    "All variables in the Household category are _conditional_\n",
    "\n",
    "```python\n",
    "if farm == 'farm':\n",
    "    sentence = 'I live in a farm!'\n",
    "else:\n",
    "    sentence = \"\"\n",
    "\n",
    "if rent >= 0:\n",
    "    sentence += \"I pay {rent} in rent.\"\n",
    "else:\n",
    "    sentence += \"\"\n",
    "    \n",
    "if vehicles > \"1 available\":\n",
    "    sentence += \"I have a car available {car emoji}\"\n",
    "else:\n",
    "    sentence += \"\"\n",
    "    \n",
    "if ssmc != \"households without a same-sex married couple\":\n",
    "    sentence += \"{rainbow emoji}\"\n",
    "else:\n",
    "    sentence += \"\"\n",
    "    \n",
    "if multgen == \"2 generations\" | \"3+ generations\":\n",
    "    sentence += \"more than 1 generation lives in my home.\"\n",
    "else:\n",
    "    sentence += \"\"\n",
    "```\n",
    "\n",
    "In some cases you'll end up with a blank string for sentence but in others you may potentially end up with a 4 part sentence: <br>_\"I live in a farm! I pay {rent} in rent. I have a car available {car emoji}. {rainbow}. More than 1 generation lives in my home.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_emoji = \"\\U0001F697\"\n",
    "rainbow_emoji = \"\\U0001F308\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter sentence\n",
    "working_df['household_sentence'] = \"\"\n",
    "\n",
    "# farm\n",
    "working_df.loc[working_df['farm'] == 'farm', \"household_sentence\"] = \"I live in a farm! \"\n",
    "\n",
    "# rent\n",
    "working_df.loc[working_df['rent'] > 0, 'household_sentence'] = working_df.loc[working_df['rent'] > 0, 'household_sentence'] + \"I pay $\" + working_df.loc[working_df['rent'] > 0, 'rent'].astype(str) + \" in rent. \"\n",
    "\n",
    "# car\n",
    "working_df.loc[working_df['vehicles'] >= '1 available', 'household_sentence'] = working_df.loc[working_df['vehicles'] >= '1 available', 'household_sentence'] + \"I have a car available \" + car_emoji + \". \"\n",
    "\n",
    "# same-sex couples\n",
    "working_df.loc[working_df['ssmc'] != 'households without a same-sex married couple', 'household_sentence'] = working_df.loc[working_df['ssmc'] != 'households without a same-sex married couple', 'household_sentence'] + rainbow_emoji + \" \"\n",
    "\n",
    "# multi-gen households\n",
    "working_df.loc[working_df['multgen'] >= '2 generations', 'household_sentence'] = working_df.loc[working_df['multgen'] >= '2 generations', 'household_sentence'] + \"More than 1 generation lives in my home. \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Work\n",
    "The work sentence is a little more complicated. We used spacy to create `occ_lemma`, `occ_tag`, and `occ_nnps`. From which we can create a \"job title\" label but for the rest we can create other fragments.\n",
    "foodstmp, empstat, labforce, occ, uhrswork, looking, availble, pwstate2, occ_lemma, occ_tag, occ_nnps\n",
    "\n",
    "```python\n",
    "if empstat == 'unemployed':\n",
    "    sentence = \"I'm unemployed\"\n",
    "    if looking == 'yes, looked for work':\n",
    "        sentence += \", but I'm still looking for a job.\"\n",
    "    else:\n",
    "        sentence += \".\"\n",
    "elif empstat == 'employed':\n",
    "    sentence = \"I work as {job label from occ_lemma or occ_tag}\"\n",
    "    if pwstate2 != 'n/a' & pwstate2 != 'california':\n",
    "        sentence += \" in {pwstate2}.\"\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    sentence = \"\"\n",
    "    \n",
    "```\n",
    "\n",
    "So you end up with something like:<br>\n",
    "_\"I'm unemployed, but I'm still looking for a job.\"_ or <br>\n",
    "_\"I'm unemployed.\"_ or <br>\n",
    "_\"I work as a scientist in Canada.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up 'occ_lemma'\n",
    "working_df['occ_lemma'] = working_df['occ_lemma'].str.split(\", ,\").str[0].str.replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter sentence\n",
    "working_df['work_sentence'] = \"\"\n",
    "\n",
    "# unemployed\n",
    "working_df.loc[(working_df['empstat'] == 'unemployed'), 'work_sentence'] = working_df['work_sentence'] + \"I'm unemployed.\"\n",
    "working_df.loc[((working_df['empstat'] == 'unemployed') & (working_df['looking'] == 'yes, looked for work')), 'work_sentence'] = \"I'm unemployed, but looking for a job. \"\n",
    "\n",
    "# employed\n",
    "condition_ing = ((working_df['occ_lemma'].str[-3:] == 'ing') & (working_df['occ_lemma'].str.split().str.len() == 1))\n",
    "condition_er = ((working_df['occ_lemma'].str[-2:] == 'er') & (working_df['occ_lemma'].str.split().str.len() == 1))\n",
    "\n",
    "working_df.loc[condition_ing, 'work_sentence'] = working_df.loc[condition_ing, 'work_sentence'] + \"I work in \" + working_df.loc[condition_ing, 'occ_lemma']\n",
    "working_df.loc[condition_er, 'work_sentence'] = working_df.loc[condition_er, 'work_sentence'] + \"I'm a \" + working_df.loc[condition_er, 'occ_lemma']\n",
    "\n",
    "# working somewhere else\n",
    "working_df.loc[((working_df['pwstate2'] > \"n/a\") & (working_df['pwstate2'] <= \"mexico\") & (working_df['pwstate2'] != 'california')), \"work_sentence\"] = working_df.loc[((working_df['pwstate2'] > \"n/a\") & (working_df['pwstate2'] <= \"mexico\")), \"work_sentence\"] + \" in \" + working_df.loc[((working_df['pwstate2'] > \"n/a\") & (working_df['pwstate2'] <= \"mexico\") & (working_df['pwstate2'] != 'california')), \"pwstate2\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Origin\n",
    "The origin sentence is a little more straight-forward.\n",
    "\n",
    "```python\n",
    "sentence = \"I was born in {bpl}.\"\n",
    "if ancestr1d != \"not classified\" | \"other\" | \"not reported\":\n",
    "    sentence += \"I am {ancestr1d}\"\n",
    "    if ancestr2d != \"not classified\" | \"other\" | \"not reported\":\n",
    "        sentence += \" and {ancestr2d}.\"\n",
    "    else:\n",
    "        sentence += \".\"\n",
    "else:\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence starter\n",
    "working_df['origin_sentence'] = \"I was born in \"\n",
    "\n",
    "# birthplace\n",
    "working_df[\"origin_sentence\"] = working_df['origin_sentence'] + working_df['bpl'].astype(str).str.split(\"(\").str[0].str.title() + \". \"\n",
    "\n",
    "# a little clean up\n",
    "working_df[\"origin_sentence\"] = working_df['origin_sentence'].str.replace(\"europe, ns\", \"europe\")\n",
    "working_df[\"origin_sentence\"] = working_df['origin_sentence'].str.replace(\"cambodia (kampuchea)\", \"cambodia\")\n",
    "working_df[\"origin_sentence\"] = working_df['origin_sentence'].str.replace(\"other ussr/russia\", \"USSR\")\n",
    "working_df[\"origin_sentence\"] = working_df['origin_sentence'].str.replace(\"asia, nec/ns\", \"asia\")\n",
    "working_df[\"origin_sentence\"] = working_df['origin_sentence'].str.replace(\"yemen arab republic (north)\", \"yemen\")\n",
    "working_df[\"origin_sentence\"] = working_df['origin_sentence'].str.replace(\"other n.e.c\", \"\")\n",
    "working_df[\"origin_sentence\"] = working_df['origin_sentence'].str.replace(\"united kingdom, ns\", \"UK\")\n",
    "working_df[\"origin_sentence\"] = working_df['origin_sentence'].str.replace(\"americas, n.s\", \"\")\n",
    "\n",
    "# ancestry\n",
    "working_df.loc[working_df['ancestr1d'] < \"united states\", 'origin_sentence'] = working_df.loc[working_df['ancestr1d'] < \"united states\", 'origin_sentence'] + \"I'm \" + working_df.loc[working_df['ancestr1d'] < \"united states\", 'ancestr1d'].astype(str).str.split(\"(\").str[0].str.title()\n",
    "working_df.loc[working_df['ancestr2d'] < \"united states\", 'origin_sentence'] = working_df.loc[working_df['ancestr2d'] < \"united states\", 'origin_sentence'] + \"and \" + working_df.loc[working_df['ancestr2d'] < \"united states\", 'ancestr2d'].astype(str).str.split(\"(\").str[0].str.title()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Language, health coverage and veteran status\n",
    "These are simple straight-forward sentences:\n",
    "```python\n",
    "if language != \"other or not reported\":\n",
    "    sentence = \"I speak {language} at home.\"\n",
    "else:\n",
    "    sentence = \"\"\n",
    "    \n",
    "if hcovany == \"with health insurance coverage\":\n",
    "    sentence = \"I have health insurance.\"\n",
    "else:\n",
    "    sentence = \"I don't have health insurance.\"\n",
    "    \n",
    "if vetstat == \"veteran\":\n",
    "    sentence = \"I am a veteran.\"\n",
    "else:\n",
    "    sentence = \"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_flag_emoji = '\\U0001F1FA\\U0001F1F8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter sentence\n",
    "working_df['lhv_sentence'] = \"\"\n",
    "\n",
    "# language\n",
    "working_df.loc[(working_df['language'] > 'n/a or blank') & (working_df['language'] < 'other or not reported'), 'lhv_sentence'] = working_df.loc[(working_df['language'] > 'n/a or blank') & (working_df['language'] < 'other or not reported'), 'lhv_sentence'] + \"I speak \" + working_df.loc[(working_df['language'] > 'n/a or blank') & (working_df['language'] < 'other or not reported'), 'language'].astype(str) + \" at home. \"\n",
    "\n",
    "# health insurance\n",
    "working_df.loc[working_df['hcovany'] == 'with health insurance coverage', 'lhv_sentence'] = working_df.loc[working_df['hcovany'] == 'with health insurance coverage', 'lhv_sentence'] + \"I have health insurance. \"\n",
    "\n",
    "# veteran\n",
    "working_df.loc[working_df['vetstat'] == 'veteran', 'lhv_sentence'] = working_df.loc[working_df['vetstat'] == 'veteran', 'lhv_sentence'] + \"I am a veteran \" + usa_flag_emoji + \" . \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Education\n",
    "```python\n",
    "if age < 18:\n",
    "    sentence = \"I am in {gradeattd}.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter sentence\n",
    "working_df['education_sentence'] = \"\"\n",
    "\n",
    "working_df.loc[working_df['age'] < '18', 'education_sentence'] = working_df.loc[working_df['age'] < '18', 'education_sentence'] + \"I am in \" + working_df.loc[working_df['age'] < '18', 'gradeattd'].astype(str) + \". \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Money\n",
    "The money sentence is a pretty straight-forward as well\n",
    "```python\n",
    "if poverty <= 100:\n",
    "    sentence = \"I live under the poverty line.\"\n",
    "else:\n",
    "    if incwages > 36000:\n",
    "        sentence = \"I make {incwage} in wages.\"\n",
    "    else:\n",
    "        sentence = \"I make {inctot} a year.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter sentence\n",
    "working_df['money_sentence'] = \"\"\n",
    "\n",
    "working_df.loc[working_df['poverty'] < 100, 'money_sentence'] = working_df.loc[working_df['poverty'] < 100, 'money_sentence'] + \"I live under the poverty line. \"\n",
    "\n",
    "working_df.loc[(working_df['incwage'] > 36000) & (working_df['incwage'] < 999998), 'money_sentence'] = working_df.loc[(working_df['incwage'] > 36000) & (working_df['incwage'] < 999998), 'money_sentence'] + \"I make $\" + working_df.loc[working_df['incwage'] > 36000, 'incwage'].astype(str) + \" in wages. \"\n",
    "\n",
    "working_df.loc[(working_df['incwage'] <= 36000) & (working_df['incwage'] < 999998) & (working_df['inctot'] < 999998) & (working_df['inctot'] > 1), 'money_sentence'] = working_df.loc[(working_df['incwage'] <= 36000) & (working_df['incwage'] < 999998) & (working_df['inctot'] < 999998) & (working_df['inctot'] > 1), 'money_sentence'] + \"I make $\" + working_df.loc[(working_df['incwage'] <= 36000) & (working_df['incwage'] < 999998) & (working_df['inctot'] < 999998) & (working_df['inctot'] > 1), 'inctot'].astype(str) + \" a year. \"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Moving\n",
    "For the moving sentence, we'll keep it simple. \n",
    "```python\n",
    "if migrate1 == \"moved between states\":\n",
    "    sentence = \"I moved from {migplac1} last year.\"\n",
    "elif migrate1 == \"abroad one year ago\":\n",
    "    if len(migplac1.split()) == 1: # if migplac1 is a one word country to keep tweets short\n",
    "        sentence = \"I moved from {migplac1} last year.\"\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    sentence = \"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter sentence\n",
    "working_df['moving_sentence'] = \"\"\n",
    "\n",
    "working_df.loc[working_df['migrate1'] == 'moved between states', 'moving_sentence'] = working_df.loc[working_df['migrate1'] == 'moved between states', 'moving_sentence'] + \"I moved from \" + working_df.loc[working_df['migrate1'] == 'moved between states', 'migplac1'].astype(str).str.title() + \" last year.\"\n",
    "\n",
    "working_df.loc[(working_df['migrate1'] == 'abroad one year ago') & (working_df['migplac1'].str.split().str.len() == 1), 'moving_sentence'] = working_df.loc[(working_df['migrate1'] == 'abroad one year ago') & (working_df['migplac1'].str.split().str.len() == 1), 'moving_sentence'] + \"I moved from \" + working_df.loc[(working_df['migrate1'] == 'abroad one year ago') & (working_df['migplac1'].str.split().str.len() == 1), 'migplac1'].astype(str).str.title() + \" last year.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Commute\n",
    "Commute is a little more complex because `carpool` depends on `tranwork` and `riders` depends on `carpool`. For `trantime` we could just say how many minutes each person commutes, if they commute, or find something interesting in the `departs` and `arrives` variable. \n",
    "\n",
    "```python\n",
    "if tranwork == \"auto, truck, or van\":\n",
    "    if carpool == 'carpools':\n",
    "        if riders > '2 people':\n",
    "            sentence = \"I carpool with {riders}\"\n",
    "        else:\n",
    "            sentence = \"\"\n",
    "    else:\n",
    "        sentence = \"I drive alone\"\n",
    "elif tranwork == \"bus or trolley bus\":\n",
    "    sentence = \"I take the bus\"\n",
    "elif tranwork == \"subway or elevated\":\n",
    "    sentence = \"I take the subway\"\n",
    "elif tranwork == \"ferryboat\":\n",
    "    sentence = \"I take a ferry\"\n",
    "elif tranwork == \"bicycle\":\n",
    "    sentence = \"I bike\"\n",
    "elif tranwork == \"railroad\":\n",
    "    sentence = \"I take the train\"\n",
    "else:\n",
    "    sentence = \"\"\n",
    "    \n",
    "if sentence != \"\":\n",
    "    if trantime > 0:\n",
    "        sentence += \" for {trantime} minutes to work\"\n",
    "    else:\n",
    "        sentence += \".\"\n",
    "        \n",
    "if trantime > 0:\n",
    "    sentence = \"I usually get there by {arrives}.\"\n",
    "      \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing arrives and departs\n",
    "working_df.loc[working_df['trantime'] > 0, 'arrives'] = working_df[working_df['trantime'] > 0]['arrives'].astype(str).str.zfill(4).str[:2] + \":\" + working_df[working_df['trantime'] > 0]['arrives'].astype(str).str.zfill(4).str[2:]\n",
    "\n",
    "working_df.loc[working_df['trantime'] > 0,'departs'] = working_df[working_df['trantime'] > 0]['departs'].astype(str).str.zfill(4).str[:2] + \":\" + working_df[working_df['trantime'] > 0]['departs'].astype(str).str.zfill(4).str[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter sentence\n",
    "working_df['commute_sentence'] = \"\"\n",
    "\n",
    "# carpool\n",
    "working_df.loc[(working_df['tranwork'] == 'auto, truck, or van') & (working_df['carpool'] == 'carpools'), 'commute_sentence'] = working_df.loc[(working_df['tranwork'] == 'auto, truck, or van') & (working_df['carpool'] == 'carpools'), 'commute_sentence'] + \"I carpool with a few people\"\n",
    "working_df.loc[(working_df['tranwork'] == 'auto, truck, or van') & (working_df['carpool'] != 'carpools'), 'commute_sentence'] = working_df.loc[(working_df['tranwork'] == 'auto, truck, or van') & (working_df['carpool'] != 'carpools'), 'commute_sentence'] + \"I drive \"\n",
    "\n",
    "# other ways\n",
    "working_df.loc[(working_df['tranwork'] == 'bus or trolley bus'), 'commute_sentence'] = working_df.loc[(working_df['tranwork'] == 'bus or trolley bus'), 'commute_sentence'] + \"I take the bus \"\n",
    "working_df.loc[(working_df['tranwork'] == 'subway or elevated'), 'commute_sentence'] = working_df.loc[(working_df['tranwork'] == 'subway or elevated'), 'commute_sentence'] + \"I take the subway \"\n",
    "working_df.loc[(working_df['tranwork'] == 'ferryboat'), 'commute_sentence'] = working_df.loc[(working_df['tranwork'] == 'ferryboat'), 'commute_sentence'] + \"I take a ferry \"\n",
    "working_df.loc[(working_df['tranwork'] == 'bicycle'), 'commute_sentence'] = working_df.loc[(working_df['tranwork'] == 'bicycle'), 'commute_sentence'] + \"I bike \"\n",
    "working_df.loc[(working_df['tranwork'] == 'railroad'), 'commute_sentence'] = working_df.loc[(working_df['tranwork'] == 'railroad'), 'commute_sentence'] + \"I take the train \"\n",
    "\n",
    "# how long\n",
    "working_df.loc[(working_df['commute_sentence'] != \"\") & (working_df['trantime'] > 0), \"commute_sentence\"] = working_df.loc[(working_df['commute_sentence'] != \"\") & (working_df['trantime'] > 0), \"commute_sentence\"] + \" for \" + working_df.loc[(working_df['commute_sentence'] != \"\") & (working_df['trantime'] > 0), \"trantime\"].astype(str) + \" minutes to work. I usually get there by \" + working_df.loc[(working_df['commute_sentence'] != \"\") & (working_df['trantime'] > 0), \"arrives\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Now we have 9 sentences to put together (language, health coverage, and veteran are grouped together)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demographics_sentence',\n",
       " 'household_sentence',\n",
       " 'work_sentence',\n",
       " 'origin_sentence',\n",
       " 'lhv_sentence',\n",
       " 'education_sentence',\n",
       " 'money_sentence',\n",
       " 'moving_sentence',\n",
       " 'commute_sentence']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_columns = [col for col in working_df.columns if '_sentence' in col]\n",
    "sentence_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will construct our final sentence by simply concatenating these. Some people will have some sentences and others won't so the `final_sentence` length will vary. We just need to make sure it stays under 280 characters to be able to tweet it out.<br>\n",
    "We'll save these in a different dataset to keep the sizes manageable (in github at least, our `working` dataset is already almost 25mb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376035, 9)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demographics_sentence</th>\n",
       "      <th>household_sentence</th>\n",
       "      <th>work_sentence</th>\n",
       "      <th>origin_sentence</th>\n",
       "      <th>lhv_sentence</th>\n",
       "      <th>education_sentence</th>\n",
       "      <th>money_sentence</th>\n",
       "      <th>moving_sentence</th>\n",
       "      <th>commute_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am 68, from Tulare ðŸ‘©</td>\n",
       "      <td>I have a car available ðŸš—.</td>\n",
       "      <td></td>\n",
       "      <td>I was born in China. I'm Taiwanese</td>\n",
       "      <td>I speak chinese at home. I have health insuran...</td>\n",
       "      <td></td>\n",
       "      <td>I make $20000 a year.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am 75, from Tulare ðŸ‘¨</td>\n",
       "      <td>I have a car available ðŸš—.</td>\n",
       "      <td></td>\n",
       "      <td>I was born in Philippines. I'm Filipino</td>\n",
       "      <td>I speak filipino, tagalog at home. I have heal...</td>\n",
       "      <td></td>\n",
       "      <td>I make $34000 a year.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am 50, from Riverside ðŸ‘©</td>\n",
       "      <td>I have a car available ðŸš—. More than 1 generati...</td>\n",
       "      <td></td>\n",
       "      <td>I was born in California. I'm African-American</td>\n",
       "      <td>I speak english at home. I have health insuran...</td>\n",
       "      <td></td>\n",
       "      <td>I make $14300 a year.</td>\n",
       "      <td></td>\n",
       "      <td>I drive  for 22 minutes to work. I usually get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am 49, from Riverside ðŸ‘¨</td>\n",
       "      <td>I have a car available ðŸš—. More than 1 generati...</td>\n",
       "      <td></td>\n",
       "      <td>I was born in California. I'm White/Caucasian</td>\n",
       "      <td>I speak english at home. I have health insuran...</td>\n",
       "      <td></td>\n",
       "      <td>I make $15700 a year.</td>\n",
       "      <td></td>\n",
       "      <td>I drive  for 141 minutes to work. I usually ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am 22, from Riverside ðŸ‘¨</td>\n",
       "      <td>I have a car available ðŸš—. More than 1 generati...</td>\n",
       "      <td>I'm unemployed, but looking for a job.</td>\n",
       "      <td>I was born in California. I'm African-American</td>\n",
       "      <td>I speak english at home. I have health insuran...</td>\n",
       "      <td></td>\n",
       "      <td>I make $11500 a year.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       demographics_sentence  \\\n",
       "0     I am 68, from Tulare ðŸ‘©   \n",
       "1     I am 75, from Tulare ðŸ‘¨   \n",
       "2  I am 50, from Riverside ðŸ‘©   \n",
       "3  I am 49, from Riverside ðŸ‘¨   \n",
       "4  I am 22, from Riverside ðŸ‘¨   \n",
       "\n",
       "                                  household_sentence  \\\n",
       "0                         I have a car available ðŸš—.    \n",
       "1                         I have a car available ðŸš—.    \n",
       "2  I have a car available ðŸš—. More than 1 generati...   \n",
       "3  I have a car available ðŸš—. More than 1 generati...   \n",
       "4  I have a car available ðŸš—. More than 1 generati...   \n",
       "\n",
       "                             work_sentence  \\\n",
       "0                                            \n",
       "1                                            \n",
       "2                                            \n",
       "3                                            \n",
       "4  I'm unemployed, but looking for a job.    \n",
       "\n",
       "                                   origin_sentence  \\\n",
       "0               I was born in China. I'm Taiwanese   \n",
       "1          I was born in Philippines. I'm Filipino   \n",
       "2  I was born in California. I'm African-American    \n",
       "3   I was born in California. I'm White/Caucasian    \n",
       "4  I was born in California. I'm African-American    \n",
       "\n",
       "                                        lhv_sentence education_sentence  \\\n",
       "0  I speak chinese at home. I have health insuran...                      \n",
       "1  I speak filipino, tagalog at home. I have heal...                      \n",
       "2  I speak english at home. I have health insuran...                      \n",
       "3  I speak english at home. I have health insuran...                      \n",
       "4  I speak english at home. I have health insuran...                      \n",
       "\n",
       "           money_sentence moving_sentence  \\\n",
       "0  I make $20000 a year.                    \n",
       "1  I make $34000 a year.                    \n",
       "2  I make $14300 a year.                    \n",
       "3  I make $15700 a year.                    \n",
       "4  I make $11500 a year.                    \n",
       "\n",
       "                                    commute_sentence  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2  I drive  for 22 minutes to work. I usually get...  \n",
       "3  I drive  for 141 minutes to work. I usually ge...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df = working_df[sentence_columns].copy()\n",
    "\n",
    "sentence_df.shape\n",
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df['final_sentence'] = sentence_df['demographics_sentence'] + sentence_df['household_sentence'] + sentence_df['work_sentence'] + sentence_df['origin_sentence'] + sentence_df['lhv_sentence'] + sentence_df['education_sentence'] + sentence_df['money_sentence'] + sentence_df['moving_sentence'] + sentence_df['commute_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.to_csv(\"../data/processed/working-101918-V2_sentence_dataset.csv\", encoding='utf-8', index = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84603553"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the lines as a text for twitterbot\n",
    "from random import shuffle\n",
    "\n",
    "with open(\"../data/processed/working-V2-sentences.txt\", 'w', encoding = 'utf-8',) as file:\n",
    "    sentences = list(sentence_df['final_sentence'])\n",
    "    shuffle(sentences)\n",
    "    text = \"\\n\".join(sentences)\n",
    "    file.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
